import math
import os
import re
import string
import sys

from ConfigParser import ConfigParser
from csv import DictReader
from collections import defaultdict

import chipsequtil

# for RefGeneDB
from util import KeyedBinaryTree


def get_file_parts(path) :
    """For <path>/<basename>.<ext>, returns 4-tuple (<path>,<basename>.<ext>,<basename>,<ext>)"""
    path,fn = os.path.split(path)
    basename,ext = os.path.splitext(fn)
    return path,fn,basename,ext

def parse_number(n) :
    """Try to cast intput first to float, then int, returning unchanged if both fail"""
    try :
        return float(n) if '.' in n else int(n)
    except :
        return n


def gerald_to_bed(gerald,min_fields=False) :
    """Convert a GERALDOutput object into a BEDOutput object

    Keyword argument *min_fields* produces BED alignment with only the first 
    three fields populated
    """

    d = {}.fromkeys(BEDOutput.FIELD_NAMES,'')

    # required BED fields
    d['chrom'] = gerald.match_chromo
    d['chromStart'] = gerald.match_pos
    d['chromEnd'] = gerald.match_pos+len(gerald.read)

    # load the remaining information
    if not min_fields :
        d['strand'] = '+' if gerald.match_strand == 'F' else '-'
        # TODO consider encoding single-read alignment score into BED score format
        # that's it?
    return BEDOutput(**d)


class GERALDOutput :
    """Container for one line of GERALD alignment output as generated by Illumina
    pipeline version >= 1.3."""

    FIELD_NAMES = ['machine',
                   'run_number',
                   'lane',
                   'tile',
                   'x_coord',
                   'y_coord',
                   'index',
                   'read_no',
                   'read',
                   'quality_string',
                   'match_chromo',
                   'match_contig',
                   'match_pos',
                   'match_strand',
                   'match_desc',
                   'single_read_score',
                   'paired_read_score',
                   'partner_chromo',
                   'partner_contig',
                   'partner_offset',
                   'partner_strand',
                   'filtering',
                   ]

    def __init__(self,line) :

        if type(line) == str :
            line = line.strip().split('\t')

        if len(line) != len(GERALDOutput.FIELD_NAMES) :
            raise GERALDOutput.FormatException('Expected %d fields in input, \
                                               found %d in line: %s'%
                                               (len(GERALDOutput.FIELD_NAMES),
                                                len(line),
                                                line))

        for fn,d in zip(GERALDOutput.FIELD_NAMES,line) :
            setattr(self,fn,parse_number(d))

    def __repr__(self) :
        return 'GERALDOutput(%s)'%repr(self.output_format())

    def output_format(self) :
        """Tab delimited string of fields as they would appear in GERALD output file"""
        return '\t'.join([str(getattr(self,d)) for d in GERALDOutput.FIELD_NAMES])+'\n'

    class FormatException(Exception) :
        """GERALD format exception, raised on malformatted input"""
        pass


class SmartFileIter :
    r"""An 'abstract' class implementing a smart file iterator.  It is essentially
    a wrapper around a collections.DictReader object that parses fields into
    Python datatypes (int, float, tuple, objects, etc) as they are iterated.
    The constructor argument *f* can be either a valid filename or a file-like
    object.  This class should not be directly instantiated - rather it should
    be subclassed with FIELD_NAMES and FIELD_TYPES defined.  FIELD_NAMES is a
    list of strings referring to the names of the fields, FIELD_TYPES is a list
    of the same length of callables that will parse the column into the desired
    format. Example::
    
      >>> s = StringIO('chr1\t0\t100\t+\nchr3\t300\t601\t-\n')
      >>> class IntervalFile(SmartFileIter):
              r'''A SmartFileIter for files with lines formatted like:
                    chrom\tstart\tend\tstrand'''
              FIELD_NAMES = ['chrom','start','end','strand']
              FIELD_TYPES= [str,int,int,lambda x: 0 if x == '+' else 1]
      >>> f = IntervalFile(s)
      >>> for r in f :
              print r['chrom'], 'length: ', r['end']-r['start'], 'strand: ',r['strand']

    ``r['start']`` and ``r['end']`` are automatically available as integers,
    so the subraction works as expected.  Arbitrary functions that accept a
    single argument and return a value may also be specified.
    """

    def __init__(self,f,skip_line_chars='#') :
        if not hasattr(self,'FIELD_NAMES') or not hasattr(self,'FIELD_TYPES') :
            raise Exception('Subclasses must define class members FIELD_NAMES and FIELD_TYPES')
        if isinstance(f,str) :
            f = open(f,'rU')
        self._dict_reader = DictReader(f,delimiter='\t',fieldnames=self.FIELD_NAMES)
        self.fieldnames = self.FIELD_NAMES
        self.curr_line = self._dict_reader.next()
        self.skip_line_chars = skip_line_chars

        # skip initial comment lines
        while self.curr_line[self.FIELD_NAMES[0]][0] in self.skip_line_chars :
            self.curr_line = self._dict_reader.next()

        if self.FIELD_NAMES[0] in self.curr_line.values() :
            self.curr_line = self._dict_reader.next()

    def __iter__(self) :
        return self

    def __getattr__(self,attr) :
        try:
            return self.__dict__[attr]
        except KeyError :
            return getattr(self._dict_reader,attr)

    def next(self) :
        """Emit the next record in the file as a dictionary with parsed values"""

        if self.curr_line is None :
            raise StopIteration()

        line = self.curr_line

        # check for comment
        while line[self.FIELD_NAMES[0]][0] in self.skip_line_chars :
            line = self.curr_line = self._dict_reader.next()

        for k,f in zip(self.FIELD_NAMES, self.FIELD_TYPES) :
            try :
                line[k] = f(line[k])
            except Exception, e :
                #sys.stderr.write('Warning: field %s on line %d could not be properly formatted, exception %s\n'%(k,self._dict_reader.reader.line_num,str(e)))
                line[k] = line[k]

        try :
            self.curr_line = self._dict_reader.next()
        except StopIteration :
            self.curr_line = None

        return line


class BEDOutput :
    """*Deprecated*: Use *BEDFile* instead.
    
    Container for one line of BED alignment output"""

    FIELD_NAMES = ['chrom',
                   'chromStart',
                   'chromEnd',
                   'name',
                   'score',
                   'strand',
                   'thickStart',
                   'thickEnd',
                   'itemRgb',
                   'blockCount',
                   'blockSizes',
                   'blockStarts',
                   ]

    def __init__(self,line='',*args,**kwargs) :

        if type(line) == str :
            line = line.strip().split('\t')

        if len(line) < 3 and any([x not in kwargs.keys() for x in ['chrom','chromStart','chromEnd']]) :
            raise BEDOutput.FormatException('Format requres at least 3 fields in \
                                            input, found %d in line: %s'%(len(line),line))
        if len(line) > len(BEDOutput.FIELD_NAMES) :
            raise BEDOutput.FormatException('Format requres at most %d fields in \
                                             input, found %d in line: %s'%
                                             (len(BEDOutput.FIELD_NAMES),len(line),line))

        empty_fields = ['']*(len(BEDOutput.FIELD_NAMES)-len(line))
        for fn,d in zip(BEDOutput.FIELD_NAMES,line+empty_fields) :
            setattr(self,fn,parse_number(d))

        # kwargs override line input
        for k,v in kwargs.items() :
            setattr(self,k,parse_number(v))

    def __repr__(self) :
        return 'BEDOutput(%s)'%(repr(self.output_format()))

    def output_format(self) :
        """Returns a string for the BED line as it would appear in a file"""
        return '\t'.join([str(getattr(self,d)) for d in BEDOutput.FIELD_NAMES])+'\n'

    class FormatException(Exception) :
        """BED format exception, raised on malformatted input"""
        pass


class BEDFile(SmartFileIter) :
    '''An iterable object containing the records in the supplied BED formatted 
    file.  Fieldnames are::

        FIELD_NAMES = ['chrom',
                       'chromStart',
                       'chromEnd',
                       'name',
                       'score',
                       'strand',
                       'thickStart',
                       'thickEnd',
                       'itemRgb',
                       'blockCount',
                       'blockSizes',
                       'blockStarts',
                       ]
    '''

    FIELD_NAMES = BEDOutput.FIELD_NAMES
    FIELD_TYPES = [str,int,int,str,float,str,int,int,str,lambda x: x.split(','), lambda x: x.split(','), lambda x: x.split(',')]


class BEDFile_dictreader(DictReader) :
    '''An iterable object (subclasses csv.DictReader) containing the records in
    the supplied BED formatted file.'''
    FIELD_NAMES = BEDOutput.FIELD_NAMES
    def __init__(self,bed) :
        '''*bed* is either a filename or a file-like object representing a BED file'''
        if isinstance(bed,str) :
            bed = open(bed,'rU')
        DictReader.__init__(self,bed,delimiter='\t',
                            fieldnames=BEDOutput.FIELD_NAMES)


class GPSFile(SmartFileIter) :
    '''An iterable object containing the records in the peaks file format
    generated by GPS. Fieldnames are::

        FIELD_NAMES = ["Position",
                       "IP",
                       "Control",
                       "Fold",
                       "Q_-lg10",
                       "P_-lg10",
                       "IPvsEMP",
                       "IPvsCTR",
                       "blank"
                      ]
    '''

    FIELD_NAMES = ["Position",
                   "IP",
                   "Control",
                   "Fold",
                   "Q_-lg10",
                   "P_-lg10",
                   "IPvsEMP",
                   "IPvsCTR",
                   "blank"
                  ]

    FIELD_TYPES = [lambda x: ('chr%s'%x.split(':')[0],int(x.split(':')[1]),x),
                   float,
                   float,
                   float,
                   float,
                   float,
                   float,
                   float,
                   str
                  ]

    def __init__(self,gps_fn) :
        f = open(gps_fn,'rU')

        SmartFileIter.__init__(self,f)


class AffyBiocFile(DictReader) :
    '''An iterable object (subclasses csv.DictReader) containing microarray data records in
    the supplied bioconductor formatted file.'''

    FIELD_NAMES = [ 'ID',
                    'Symbol',
                    'Name',
                    'M',
                    'A',
                    't',
                    'P.Value',
                    'B'
                  ]

    def __init__(self,affyfn) :
        '''*affyfn* is either a filename or a file-like object representing a bioconductor output file'''
        if isinstance(affyfn,str) :
            bed = open(bed,'rU')
        DictReader.__init__(self,bed,delimiter='\t',
                            fieldnames=BEDOutput.FIELD_NAMES)


class RefGeneOutput(object) :
    # http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/refGene.sql
    FIELD_NAMES = ['bin',
                   'name',
                   'chrom',
                   'strand',
                   'txStart',
                   'txEnd',
                   'cdsStart',
                   'cdsEnd',
                   'exonCount',
                   'exonStarts',
                   'exonEnds',
                   'score',
                   'name2',
                   'cdsStartStat',
                   'cdsEndStat',
                   'exonFrames',]


class RefGeneFile(DictReader) :
    '''An iterable object (subclasses csv.DictReader) containing the records in
    the supplied BED formatted file'''
    def __init__(self,refGene_fn) :
        refGene_f = open(refGene_fn,'rU')
        # check for header
        first_line = refGene_f.next()
        if not first_line.strip().startswith('#') :
            refGene_f.seek(0) # first line not header, reset the file pointer
        DictReader.__init__(self,refGene_f,delimiter='\t',fieldnames=RefGeneOutput.FIELD_NAMES)

class RefGeneFile_nottested(SmartFileIter) :
    '''An iterable object containing the records in the supplied UCSC RefGene 
    refFlat formatted file (see e.g. 
    http://hgdownload.cse.ucsc.edu/goldenPath/hg19/database/refGene.sql)'''
    FIELD_NAMES = ['bin',
                   'name',
                   'chrom',
                   'strand',
                   'txStart',
                   'txEnd',
                   'cdsStart',
                   'cdsEnd',
                   'exonCount',
                   'exonStarts',
                   'exonEnds',
                   'score',
                   'name2',
                   'cdsStartStat',
                   'cdsEndStat',
                   'exonFrames',]
    FIELD_TYPES = [str,str,str,str,int,int,int,int,int,
                   lambda x: [int(y) for y in x.split(',') if len(y) > 0],
                   lambda x: [int(y) for y in x.split(',') if len(y) > 0],
                   float,
                   str,str,str,str]

class KnownGeneFile(SmartFileIter) :
    '''An iterable that parses UCSC's KnownGene gene annotation files.  Field 
    names are::

        FIELD_NAMES = [ 'name',
                        'chrom',
                        'strand',
                        'txStart',
                        'txEnd',
                        'cdsStart',
                        'cdsEnd',
                        'exonCount',
                        'exonStarts',
                        'exonEnds',
                        'proteinID',
                        'alignID',
                      ]
'''

    FIELD_NAMES = [ 'name',
                    'chrom',
                    'strand',
                    'txStart',
                    'txEnd',
                    'cdsStart',
                    'cdsEnd',
                    'exonCount',
                    'exonStarts',
                    'exonEnds',
                    'proteinID',
                    'alignID',
                  ]

    # function pointers for correct formatting of field names
    FIELD_TYPES = [ str,
                    str,
                    str,
                    int,
                    int,
                    int,
                    int,
                    lambda x: [int(y) for y in x.split(',') if len(y) > 0],
                    lambda x: [int(y) for y in x.split(',') if len(y) > 0],
                    lambda x: [int(y) for y in x.split(',') if len(y) > 0],
                    str,
                    str,
                  ]

    def __init__(self,kg_fn) :
        self.meta_data = []
        self.file_info = {}
        f = open(kg_fn,'rU')
        self._dict_reader = DictReader(f,delimiter='\t',fieldnames=KnownGeneFile.FIELD_NAMES)

    def __iter__(self) :
        return self

    def next(self) :
        line = self._dict_reader.next()
        for k,f in zip(self.FIELD_NAMES,self.FIELD_TYPES) :
            line[k] = f(line[k])
        return line


#TODO maybe, finish this
class RefGeneDB :
    '''A class for querying RefGene annotation files. NOT DONE.'''

    def __init__(self,refgene_fn) :
        self._chrom_trees = defaultdict(KeyedBinaryTree)
        refgene_f = RefGeneFile(refgene_fn)
        genes = defaultdict(list)
        for gene in refgene_f :
            genes[gene['chrom']].append(gene)

        # do stuff to ensure a balanced tree for each chromosome
        for chrom,gene_list in genes.items() :
            gene_list.sort(key=lambda x: int(x['txStart']))
            first_half, second_half = gene_list[:len(gene_list)/2],gene_list[len(gene_list)/2:]
            first_half.reverse()
            for i in range(min(len(first_half,second_half))) :
                to_add = first_half.pop(i)
                self._chrom_trees[chrom].addNode(int(to_add['txStart']),to_add)


class MACSFile(SmartFileIter) :
    '''An iterable object containing the records in the supplied MACS peak file.
    This class parses the comments found in the header of MACS peak files and
    extracts metadata into the member dictionary **file_info**.  Here is an example
    metadata dictionary::
    
      >>> f = MACSFile('macs_peaks.xls')
      >>> f.file_info
          {'ChIP-seq file': 'experiment_read_alignments.sam',
           'MACS version': '1.4.0rc2 20110214',
           'Range for calculating regional lambda': '1000 bps and 10000 bps',
           'Redundant rate in control': 0.72999999999999998,
           'Redundant rate in treatment': 0.080000000000000002,
           'band width': 300,
           'control file': 'control_read_alignments.sam',
           'd': 203,
           'effective genome size': 2110000000.0,
           'format': 'SAM',
           'maximum duplicate tags at the same position in control': 2,
           'maximum duplicate tags at the same position in treatment': 2,
           'model fold': '10,30',
           'name': 'my_awesome_ChIP',
           'pvalue cutoff': 1.0000000000000001e-05,
           'tag size': 36,
           'tags after filtering in control': 7879454,
           'tags after filtering in treatment': 23927336,
           'total tags in control': 29703098,
           'total tags in treatment': 26092366}

    The complete header can be found as a list in the **meta_data** member with
    one comment per item.  The field names available are::

        FIELD_NAMES = ['chr',
                       'start',
                       'end',
                       'length',
                       'summit',
                       'tags',
                       '-10*log10(pvalue)',
                       'fold_enrichment',
                       'FDR(%)',
                      ]

    '''
    FIELD_NAMES = ['chr',
                   'start',
                   'end',
                   'length',
                   'summit',
                   'tags',
                   '-10*log10(pvalue)',
                   'fold_enrichment',
                   'FDR(%)',
                  ]

    FIELD_TYPES = [str,
                   int,
                   int,
                   int,
                   int,
                   int,
                   float,
                   float,
                   float
                  ]

    _METADATA_REGEXES = [
            u'# This file is generated by (MACS version) (.*)',
            u'# (name) = (.*)',
            u'# (format) = (.*)',
            u'# (ChIP-seq file) = (.*)',
            u'# (control file) = (.*)',
            u'# (effective genome size) = (.*)',
            u'# (band width) = (\d+)',
            u'# (model fold) = (.*)',
            u'# (pvalue cutoff) = (.*)',
            u'# (Range for calculating regional lambda) is: (.*)',
            u'# (tag size) is determined as (\d+) bps',
            u'# (total tags in treatment): (\d+)',
            u'# (tags after filtering in treatment): (\d+)',
            u'# (maximum duplicate tags at the same position in treatment) = (\d+)',
            u'# (Redundant rate in treatment): (.*)',
            u'# (total tags in control): (.*)',
            u'# (tags after filtering in control): (.*)',
            u'# (maximum duplicate tags at the same position in control) = (\d+)',
            u'# (Redundant rate in control): (.*)',
            u'# (d) = (\d+)'
            ]

    def __init__(self,macs_fn) :
        self.meta_data = []
        self.file_info = {}
        if isinstance(macs_fn,str) :
            f = open(macs_fn,'rU')
        else :
            f = macs_fn
        done_with_header = False
        while not done_with_header :
            l = f.next().strip()
            if l.startswith('#') :
                for regex in MACSFile._METADATA_REGEXES :
                    m = re.search(regex,l)
                    if m is not None :
                        self.file_info[m.group(1).strip()] = parse_number(m.group(2).strip())
                self.meta_data.append(l)
            elif l.startswith('\t'.join(MACSOutput.FIELD_NAMES[:5])) :
                self.meta_data.append(l)
                done_with_header = True

        SmartFileIter.__init__(self,f)


# for backwards compatibility, use MACSFile instead...?
class MACSOutput(object) :
    FIELD_NAMES = MACSFile.FIELD_NAMES

GLOBAL_SETTINGS_FN = os.path.join(os.path.split(chipsequtil.__file__)[0],'org_settings.cfg')
LOCAL_SETTINGS_FN = os.path.expanduser(os.path.join('~','.org_settings.cfg'))
_ALL_SETTINGS, _LOCAL_SETTINGS, _GLOBAL_SETTINGS = range(3)

def _get_org_settings(org_key=None,addnl_configs=[],src=_ALL_SETTINGS) :
    """Utility function used by get_org_settings and get_all_settings, should \
    not be called directly"""

    config = ConfigParser()
    chipsequtil_base =     conf_fns = []
    if src in [_LOCAL_SETTINGS, _ALL_SETTINGS] :
        conf_fns.append(LOCAL_SETTINGS_FN)
    if src in [_GLOBAL_SETTINGS, _ALL_SETTINGS] :
        conf_fns.append(GLOBAL_SETTINGS_FN)
    config.read(conf_fns+addnl_configs)

    d = {}
    if org_key is None :
        for sec in config.sections() :
            # try to cast numeric-looking arguments into float, int
            d[sec] = dict([(k,parse_number(v)) for k,v in config.items(sec)])
    else :
        d = dict([(k,parse_number(v)) for k,v in config.items(org_key)])

    return d

##SJCG commented this out for re-release...
# def get_org_settings(org_key,addnl_configs=[]) :
#     '''Returns a dict of setting/path values for a given organism as specified
#     in system-wide and user's settings. *org_key* is the organism name as found
#     in the config file, *e.g.* mm9.  *addnl_configs* are filenames of other
#     configuration files to add to the set of settings, usually not needed.
#     Example usage::
    
#       >>> org_d = get_org_settings('mm9')
#       >>> org_d
#           {'affy_to_known_path': '/nfs/genomes/mouse_gp_jul_07/anno/knownToMOE43-mm9.txt',
#            'annotation_path': '/nfs/genomes/mouse_gp_jul_07/anno/refFlat-mm9.txt',
#            'description': "UCSC mm9 (July '07 build) with full TRANSFAC hypothesis set",
#            'genome': 'mm9',
#            'genome_dir': '/nfs/genomes/mouse_gp_jul_07',
#            'genome_size': 2107000000,
#            'known_gene_anno_path': '/nfs/genomes/mouse_gp_jul_07/anno/knownGene-mm9.txt',
#            'known_gene_xref_path': '/nfs/genomes/mouse_gp_jul_07/anno/kgXref-mm9.txt',
#            'refgene_anno_path': '/nfs/genomes/mouse_gp_jul_07/anno/refFlat-mm9.txt',
#            'theme_hypotheses': '/nfs/vendata/cwng/TRANSFAC/2010_transfac_vert_all_filtic9.tamo',
#            'theme_markov': '/nfs/data/cwng/chipseq/hypotheses/Mouse.markov',
#            'ucsc_chrom_sizes': '/nfs/genomes/mouse_gp_jul_07/mm9.chrom.sizes'}
#       >>> get_org_settings('mm9')['genome_dir']
#           '/nfs/genomes/mouse_gp_jul_07'

#     '''
#     return _get_org_settings(org_key,addnl_configs=addnl_configs)


# def get_all_settings(addnl_configs=[]) :
#     '''Returns a dict of setting/path values for every organism as specified in
#     system-wide and user's settings.'''
#     return _get_org_settings(None,addnl_configs=addnl_configs)


# def get_global_settings() :
#     '''Returns a dict of the global setting/path values installed with the
#     package.'''
#     return _get_org_settings(None,src=_GLOBAL_SETTINGS)


# def get_local_settings() :
#     '''Returns a dict of the current user's setting/path values taken from
#     ~/.org_settings.cfg if it exists.'''
#     return _get_org_settings(None,src=_LOCAL_SETTINGS)


# def check_org_settings(org_key,setting_list) :
#     '''Returns true if all setting names in *setting_list* are found in the 
#     org settings for organism *org_key* and false otherwise. Mostly used
#     internally to sanity check org settings.'''
#     settings = get_org_settings(org_key)
#     return all([s in settings.keys() for s in setting_list])


RC_MAP = string.maketrans('acgtACGT','tgcaTGCA')
def reverse_complement(seq) :
    """Reverse complements nucleotide string *seq*.  Leaves non-nucleotide characters uneffected."""
    return seq.translate(RC_MAP)[::-1]


def get_gc_content(seq) :
    '''returns the GC content of a DNA sequence as python string'''
    seq = seq.lower()
    return (seq.count('c')+seq.count('g'))/float(len(seq))


def get_gc_content_distribution(sequences,bins=100) :
    '''returns a list of 
    provided sequences.  Approximation is performed by binning.'''
    gc_contents = [get_gc_content(s) for s in sequences]
    gc_contents.sort()

    # count up the sequences for each bin
    bin_counts = [0.]*bins
    for c in gc_contents :
        sample_bin = int(math.floor(c*bins))
        bin_counts[sample_bin] += 1

    # normalize bin counts
    norm_bins = [x/len(sequences) for x in bin_counts]

    # create a closure for this set of sequences
    #def f(seq) :
    #    gc = get_gc_content(seq)
    #    return norm_bins[int(math.floor(gc*bins))]

    return norm_bins


def get_size_distribution(sequences) :
    return (len(s) for s in sequences)



